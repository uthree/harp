# 並列化処理のプラン
並列化は主にGPU向けの方法を採用する。CPU上でのOpenMPを使った最適化の場合は、カーネル呼び出し時にparallel for文を回す。
これはGPU向けコードをCPUで動かすラッパーとしての役割がある。
この機能はRenderer側で実装し、Rendererがデバイスの違いを吸収する。

## Load, Storeノードの追加
AssignやVarは単純に変数から値を読み込んだり書き込んだりを表すが、Load,Storeは配列単位での（メモリ空間をまとめて読み書き）する処理を表す。

## "Kernel" AstNodeの追加
Functionノードと同じ機能を持つが、立ち上げるスレッドやグループの数などの情報を持つ。
### 引数
通常の引数に加えて、lid(グループ内でのスレッド番号), gid(ループ番号) を持つ。
これらは3次元のベクトルだが簡略化のため最初の要素(lid.x, gid.x)のみを使う。

## "CallKernel" AstNodeの追加
CallFunctionと同じ機能をもち、立ち上げるスレッドやグループの数などを指定する項目を追加。

## AstOptimizerのSuggesterの追加
### "Kernelize"
関数ノード(Function)をカーネル(Kernel)に変換する。初期状態でのスレッド数およびグループ数は1で固定。

### "Parallelize"
Kernel内の一番外側のforループ（Rangeノード）をグループまたはスレッドで並列化する。結果的にfor文は消滅する。

#### 具体的な流れ
```
一番外側のforループがgidで並列化済み:
    一番外側のループがlidで並列化済み:
        何も提案せず終了
    でなければ:
        lidによる並列化を提案
でなければ:
    gidによる並列化を提案
```

#### メモリアクセス解析について
この並列化において、メモリアクセスの境界をどのように考慮すべきかが課題となる。
具体的には、ReductionやCumulativeで縮約・累積する軸については並列化不可能で、element-wiseな演算を行う軸については縮約可能である。

そこで、以下のような方法が考えられる。
1. Lower時にRangeノードにそれがリダクションのループなのか、累積のループなのか、あるいは単なるElementwise演算のためのループなのかのラベルを付与する。
2. 書き込み命令のポインタを確認して競合していないかチェックする。

前者（1）は実装自体は簡単かもしれないが、LowererとRangeノードの書き換えが必要で、ループ展開などのSuggest時にもラベルを付与しなければいけない。
後者（2）は、書き込みアドレスを解析する必要があるための難しさがある。

### "RangeExtract"
関数の中のトップレベルのRangeノードをを別の独立した関数として切り出す。
これは主にKernelize前の一手として使うことが多い。
既にKernelizeされた関数には適用しない。