# Harp Design Document

This document outlines the core design principles of the Harp library, focusing on its computation graph, operator hierarchy, and tensor interface.

## Core Concepts

The design revolves around two main graph representations: the low-level `Node` graph for scalar operations and the high-level `Tensor` graph for multi-dimensional array operations.

### 1. `Node` Graph

-   The fundamental computation graph, where each node represents a scalar value and a single operation (e.g., `OpAdd`, `Sin`).
-   This graph is the target for compilation and optimization.

### 2. `Tensor` Graph

-   **`Tensor`**: The primary user-facing struct. It's a lightweight, reference-counted handle to its underlying computation definition.
-   **`TensorData`**: Contains the operator and source tensors (inputs) that define a node in the tensor graph.
-   **Lazy Evaluation**: Tensor operations do not perform computations immediately. Instead, they build a high-level graph representing the sequence of operations. Actual computation is deferred until a backend compiles and executes the graph.

### 3. Operator Hierarchy

Harp uses a unified set of operator structs (e.g., `OpAdd`, `OpMul`) for both graphs, categorized by a system of traits to define their behavior and properties. This is crucial for abstraction and optimization.

-   **`Operator`**: The base trait for all operations.
-   **`PrimitiveOp`**: A marker for the most basic operators that a compiler backend must implement. These are the fundamental building blocks of all computations.
-   **`FusedOp`**: A trait for composite operators that can be decomposed into a subgraph of more primitive ones. This allows for high-level abstractions without increasing the complexity of the compiler backend.
-   **`Input` Operator**: A special primitive operator that represents an input buffer (e.g., a pointer to an array) passed as an argument to a compiled kernel. This formalizes the data entry points for the computation graph.
-   **`Load` and `Store` Operators**: These are primitive operators that represent memory access. They are no longer simple markers but are now nodes in the graph that take other nodes as input.
    -   `Load`: Takes two source nodes: an `Input` node (the buffer) and an index node.
    -   `Store`: Takes three source nodes: an `Input` node (the buffer), an index node, and the value node to be stored.
-   **`Loop` and `LoopVariable`**: Operators to explicitly represent loops. `Loop` takes a count and a body graph, while `LoopVariable` represents the loop's induction variable (e.g., `i`) within the body.

### 4. Tensor Initialization and Shape Manipulation

-   **Shape Representation**: Shapes are represented by `Vec<usize>` for consistency with Rust's standard library indexing and memory management.
-   **Type-Safe Constants**: Generic methods like `Tensor::full` use the `DType` trait to preserve type information (e.g., `f32`, `i64`) within the graph.
-   **Memory-Efficient Initialization**: `Tensor::full`, `zeros`, and `ones` are implemented as memory-efficient view operations using the `Expand` operator.
-   **Declarative Randomness**: `Tensor::uniform` and `Tensor::randn` place `OpUniform` or `OpRandn` operators in the graph, deferring actual random number generation to the execution engine.

### 5. API and Tooling

-   **`prelude` Module**: To improve ergonomics, a `prelude` module is provided to conveniently import the most commonly used items.
-   **`ToDot` Trait**: A common trait for graph visualization, implemented for both `Node` and `Tensor`.

## 6. Backend and Code Generation

The ultimate goal of Harp is to compile the `Node` graph into high-performance code for various backends like C, CUDA, or Metal.

### a. Directory Structure

-   All backend-related modules are organized under `src/backend/` for clarity and future expansion.

### b. Code Generation Abstraction

-   **`CodeGenerator` (The "Planner"):** This engine is language-agnostic. It traverses the `Node` graph and produces a list of abstract `Instruction`s (e.g., `DeclareVariable`, `Loop`, `Statement`). It understands the *semantics* of the graph (e.g., `FusedOp` fallback, loop scoping) but knows nothing about the target language's syntax.
-   **`Renderer` (The "Writer"):** This trait is implemented for each target language (e.g., `CRenderer`). Its sole responsibility is to take the list of abstract `Instruction`s from the `CodeGenerator` and translate it into a syntactically correct string for that specific language.
-   This separation of concerns ensures that the complex graph traversal logic is written only once, and adding a new language backend only requires implementing the `Renderer` trait.

### c. C Backend Example

-   **`CRenderer`**: Implements the `Renderer` trait to convert `Instruction`s into C code.
-   **`CCompiler`**: Implements the `Compiler` trait. It uses `gcc` to compile the C code generated by `CRenderer` into a shared library (`.so` or `.dylib`).
-   **`CKernel`**: Implements the `Kernel` trait. It uses the `libloading` crate to load the compiled shared library, get a function pointer to the kernel (e.g., `compute`), and execute it.

### d. Future Components (Design)

-   **`Compiler` Trait**: Will be responsible for taking the generated source code string and invoking an external compiler (e.g., `gcc`, `nvcc`) to produce a runnable artifact.
-   **`Kernel` Trait**: A handle to a compiled, loadable kernel, likely representing a function pointer from a dynamic library.
-   **`Backend` Trait**: A high-level interface (e.g., `Cuda<0>`) that brings together the `Renderer`, `Compiler`, and device management.
-   **`DeviceTensor` Trait**: Represents a tensor whose data resides on a specific device (e.g., a GPU). It will manage device memory and provide methods for data transfer.
